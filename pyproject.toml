[project]
name = "llama"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = "<3.13,>=3.10"
dependencies = [
    "openai (>=1.63.0,<2.0.0)",
    "python-dotenv (>=1.0.1,<2.0.0)",
    "numpy (==1.26.0)",
    "sentence-transformers (>=3.4.1,<4.0.0)",
    "torch (==2.2.2)",
    "cryptography (>=44.0.1,<45.0.0)",
    "simple-ddl-parser (>=1.7.1,<2.0.0)",
    "tiktoken (>=0.9.0,<0.10.0)",
    "flagembedding (>=1.3.4,<2.0.0)",
    "llama-index (>=0.12.19,<0.13.0)",
    "llama-index-embeddings-huggingface (>=0.5.1,<0.6.0)",
    "openpyxl (>=3.1.5,<4.0.0)",
    "llama-index-llms-openai-like (>=0.3.3,<0.4.0)",
    "llama-index-storage-kvstore-redis (>=0.3.0,<0.4.0)",
    "llama-index-storage-docstore-redis (>=0.3.0,<0.4.0)",
    "llama-index-callbacks-langfuse (>=0.3.0,<0.4.0)",
    "llama-deploy (>=0.6.1,<0.7.0)",
    "chainlit (>=2.2.1,<3.0.0)",
    "llama-index-llms-deepseek (>=0.1.1,<0.2.0)",
    "llama-index-postprocessor-flag-embedding-reranker (>=0.3.0,<0.4.0)",
    "pymssql (>=2.3.2,<3.0.0)",
    "sqlalchemy (>=2.0.39,<3.0.0)",
    "asyncpg (>=0.30.0,<0.31.0)",
    "aioodbc (>=0.5.0,<0.6.0)",
    "opentelemetry-sdk (>=1.31.0,<2.0.0)",
    "fastapi>=0.115.11",
    "aiostream>=0.6.4",
    "llama-index-llms-xinference>=0.3.0",
    "llama-index-vector-stores-milvus>=0.5.0",
]

[dependency-groups]
dev = [
    "sqlacodegen >=3.0.0,<4.0.0"
]

[[tool.uv.index]]
url = "https://pypi.tuna.tsinghua.edu.cn/simple"
default = true
